{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNM8vqqMSsHnwFf9c5RRAcc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlos-alves-one/-ML-Zoomcamp-Week-5/blob/main/ML_Zoomcamp_Week_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goldsmiths University of London\n",
        "**Author....: Carlos Manuel de Oliveira Alves**<br>\n",
        "**Student..: cdeol003**<br>\n",
        "**Created..: 03/10/2022**"
      ],
      "metadata": {
        "id": "i6Ma_jB9wsko"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fn6xjOAtwp3M"
      },
      "outputs": [],
      "source": [
        "# Import all necessay libraries that we will use in this project\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Import the library warnings to ignore the warnings from the system\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preparation:\n",
        "\n",
        "# Read the dataset, store it in dataframe\n",
        "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "\n",
        "# Make the categorical data of the dataframe consistent \n",
        "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "\n",
        "categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
        "\n",
        "for col in categorical_columns:\n",
        "  df[col] = df[col].str.lower().str.replace(' ', '_')\n",
        "\n",
        "# Convert a serie of the dataframe to a number\n",
        "df.totalcharges = pd.to_numeric(df.totalcharges, errors='coerce')\n",
        "\n",
        "# Fill the missing values of the total charges serie with zeros\n",
        "df.totalcharges = df.totalcharges.fillna(0)\n",
        "\n",
        "# Update the churn data with numbers\n",
        "df.churn = (df.churn == 'yes').astype(int)"
      ],
      "metadata": {
        "id": "ZMwYnw4m0KUv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sizes of the datasets with 20% and use random state so the results are reproducible\n",
        "# the full train dataset has 80% and the test 20%\n",
        "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)"
      ],
      "metadata": {
        "id": "QxcW7Vdz3fE1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list with numerical variables from the dataframe\n",
        "numerical = ['tenure','monthlycharges','totalcharges']\n",
        "\n",
        "# Create a list with categorical variables from the dataframe\n",
        "categorical = ['gender', 'seniorcitizen', 'partner', 'dependents',\n",
        "    'phoneservice', 'multiplelines', 'internetservice',\n",
        "    'onlinesecurity', 'onlinebackup', 'deviceprotection', 'techsupport',\n",
        "    'streamingtv', 'streamingmovies', 'contract', 'paperlessbilling',\n",
        "    'paymentmethod']"
      ],
      "metadata": {
        "id": "ENEJ1fej32YK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function for training\n",
        "def train(data_train, y_train, C=1.0):\n",
        "    \n",
        "    # Create dictionaries that extract from our dataframe categoricl and numerical variables\n",
        "    dicts = data_train[categorical+numerical].to_dict(orient='records')\n",
        "\n",
        "    # Create a new instance of the DictVectorizer class without sparse\n",
        "    dv = DictVectorizer(sparse=False)\n",
        "    \n",
        "    # Use the function transform with our DictVectorizer\n",
        "    X_train = dv.fit_transform(dicts)\n",
        "\n",
        "    # Create a model logistic regression and define the parameter and duration\n",
        "    model = LogisticRegression(C=C, max_iter=1000)\n",
        "    \n",
        "    # For training the model we use the fit method\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Return the DictVectorizer and model\n",
        "    return dv, model"
      ],
      "metadata": {
        "id": "uvJFRQbP4RUL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function for predict\n",
        "def predict(data, dv, model):\n",
        "\n",
        "    # Convert the dataframe into a list of dictionaries\n",
        "    dicts = data[categorical+numerical].to_dict(orient='records')\n",
        "\n",
        "    # Creates the feature matrix using the vectorizer\n",
        "    X = dv.transform(dicts)\n",
        "\n",
        "    # Use the model predict proba and take the second column\n",
        "    y_pred = model.predict_proba(X)[:, 1]\n",
        "\n",
        "    # Return our prediction\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "6hY0YelL4vGR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameters of the model\n",
        "C = 1.0\n",
        "n_splits = 5"
      ],
      "metadata": {
        "id": "_MYGpDQr46lV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the function KFold to split the data in 5 parts and seed 1\n",
        "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
        "\n",
        "# Create a list with scores\n",
        "scores = []\n",
        "\n",
        "# Iterate over the full train dataframe using the function split together with train and val indexes\n",
        "for train_idx, val_idx in kfold.split(df_full_train):\n",
        "\n",
        "    # Use iloc to select a part of the full train dataframe for train\n",
        "    df_train = df_full_train.iloc[train_idx]\n",
        "\n",
        "    # Use iloc to select a part of the full train dataframe for validation\n",
        "    df_val = df_full_train.iloc[val_idx]\n",
        "\n",
        "    # Use iloc to select a part of the full train dataframe for train and validation\n",
        "    y_train = df_train.churn.values\n",
        "    y_val = df_val.churn.values\n",
        "\n",
        "    # Call function train and store results of dv and model\n",
        "    dv, model = train(df_train, y_train,C=1)\n",
        "\n",
        "    # Call the function predict and use with our validation datset\n",
        "    y_pred = predict(df_val, dv, model)\n",
        "    \n",
        "    # Compute and store the ROC AUC score\n",
        "    auc = roc_auc_score(y_val, y_pred)\n",
        "    \n",
        "    # After evaluate the model we store the results\n",
        "    scores.append(auc)\n",
        "\n",
        "# Print the mean score and standard deviation\n",
        "print(f'C={C} {np.mean(scores):.3f} +- {np.std(scores):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-mSk0_G5I3Q",
        "outputId": "b02e6fdf-9f59-4366-c0ca-89ef126bd1fc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=1.0 0.840 +- 0.008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2UCqLYgu5_Vf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}